# app.py

import streamlit as st
from ai_assistant import create_rag_chain  # ä»æˆ‘ä»¬çš„æ ¸å¿ƒé€»è¾‘æ–‡ä»¶ä¸­å¯¼å…¥å‡½æ•°
# ---é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="æˆ‘çš„ä¸“å±AIçŸ¥è¯†åº“åŠ©æ‰‹", page_icon="ğŸ¤–")
st.title("ğŸ¤– çŸ¥è¯†åº“æ™ºèƒ½é—®ç­”åŠ©æ‰‹")

# --- åˆå§‹åŒ– ---
# ä½¿ç”¨ st.cache_resource æ¥ç¼“å­˜æˆ‘ä»¬çš„RAG chainï¼Œé¿å…æ¯æ¬¡éƒ½é‡æ–°åŠ è½½æ¨¡å‹å’Œæ–‡æ¡£
# è¿™ä¼šè®©åº”ç”¨å“åº”é€Ÿåº¦æ›´å¿«
@st.cache_resource
def load_chain():
    return create_rag_chain()

# åœ¨ä¾§è¾¹æ åˆ›å»ºä¸€ä¸ªè¯´æ˜
with st.sidebar:
    st.header("å…³äº")
    st.markdown("""
    æœ¬é¡¹ç›®åŸºäº **LangChain** å’Œ **Streamlit** æ„å»ºã€‚
    å®ƒèƒ½è¯»å– `knowledge.pdfçš„å†…å®¹ï¼Œå¹¶æ ¹æ®å…¶å›ç­”ä½ çš„é—®é¢˜ã€‚
    """)

# åŠ è½½RAG chain
chain = load_chain()

# ---èŠå¤©ç•Œé¢ ---

# åˆå§‹åŒ–èŠå¤©å†å² (ä½¿ç”¨session_state)
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è·å–ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·åœ¨è¿™é‡Œè¾“å…¥ä½ å…³äºçŸ¥è¯†åº“çš„é—®é¢˜..."):
    # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å†å²è®°å½•å¹¶æ˜¾ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # è·å–AIçš„å›ç­”    
    with st.chat_message("assistant"):
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­..."):
            # è°ƒç”¨æˆ‘ä»¬çš„RAG chain
            response = chain.invoke({"input": prompt})
            ai_answer = response["answer"]
            st.markdown(ai_answer)
    
    # å°†AIçš„å›ç­”ä¹Ÿæ·»åŠ åˆ°å†å²è®°å½•
    st.session_state.messages.append({"role": "assistant", "content": ai_answer})
